{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ab5b8d",
   "metadata": {},
   "source": [
    "# Download Google Images by Keyword using Selenium\n",
    "\n",
    "**Steps:**\n",
    "- Check Google Chrome version, and download [ChromeDriver](https://chromedriver.chromium.org/downloads) according to your version\n",
    "- Take note of where you put your ChromeDriver.exe, you will need it :)\n",
    "- `pip install selenium` and `pip install Pillow`\n",
    "- Funny, Pillow is one of the powerful tools that can colorized grayscale picture, but here, we are using it to save Image and also, to save as both normal color version, and grayscale version `img = img.convert(\"L\")`\n",
    "- Here I focus in downloading images, not yet gray scaled it lol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00458dc",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62519779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0bf5e",
   "metadata": {},
   "source": [
    "### Example of Selenium Webdriver\n",
    "- Input specific website for your web browser, just an example to better understand Selenium lol, don't need to run if you don't wanna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1f1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where I place the chromedriver.exe\n",
    "DRIVER_PATH = \"C:\\\\Users\\\\Alice\\\\Desktop\\\\PYTHON\\\\PIC 16B\\\\PROJECT\\\\chromedriver.exe\"\n",
    "\n",
    "# Open Webdriver, then get google main search page \"https://google.com\"\n",
    "wd = selenium.webdriver.Chrome(executable_path = DRIVER_PATH)\n",
    "wd.get('https://google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbda65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect google search page --> select search box = 'input.gLFyf'\n",
    "search_box = wd.find_element_by_css_selector('input.gLFyf')\n",
    "\n",
    "# send keyword 'Portraits in search box\n",
    "search_box.send_keys('Portraits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd144a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the webdriver\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cff87b",
   "metadata": {},
   "source": [
    "# Fetch Images Urls on Google Image Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f2c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER_PATH = \"C:\\\\Users\\\\Alice\\\\Desktop\\\\PYTHON\\\\PIC 16B\\\\PROJECT\\\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e151c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image_urls(query:str, max_links_to_fetch:int, wd:webdriver):\n",
    "    \"\"\"\n",
    "    Fetch google image links\n",
    "    Argurment:\n",
    "    - query:search term, example: nature, portrait,...\n",
    "    - max_link_to_fetch: as name indicate\n",
    "    - wd: instantiate webdriver (DRIVER_PATH = global variable)\n",
    "        (wd = webdriver.Chrome(executable_path = DRIVER_PATH \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Indicate to keep scrolling to get more images\n",
    "    def scroll_to_end(wd):\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "    # build the google query, just a image search url for random image with input query {q}\n",
    "    search_url = \"https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img\"\n",
    "\n",
    "    # load the page with search_url and input keyword query\n",
    "    wd.get(search_url.format(q=query))\n",
    "    \n",
    "    # initiate \n",
    "    image_urls = set()\n",
    "    image_count = 0\n",
    "    results_start = 0\n",
    "    \n",
    "    # loops to get all image links < max input\n",
    "    while image_count < max_links_to_fetch:\n",
    "        scroll_to_end(wd)\n",
    "\n",
    "        # get all image thumbnail results, inspect for css of all images = img.Q4LuWd (the small images)\n",
    "        thumbnail_results = wd.find_elements_by_css_selector(\"img.Q4LuWd\")\n",
    "        number_results = len(thumbnail_results)\n",
    "        \n",
    "        \n",
    "        # for each images in css thumbnails list \n",
    "        for img in thumbnail_results[results_start:number_results]:\n",
    "            # try to click every thumbnail such that we can get the real image behind it\n",
    "            try:\n",
    "                img.click()\n",
    "                \n",
    "            # some link can't be click or exception were raisedm, pass with continue\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            # extract image urls: after click google image, a bigger images will shows up --> css = img.n3VNCb\n",
    "            # this is where we can actually get the exact image urls to download\n",
    "            actual_images = wd.find_elements_by_css_selector('img.n3VNCb')\n",
    "            \n",
    "            # for each image in the image urls list, the links is under src attribute, so check both src att and http in link\n",
    "            for actual_image in actual_images:\n",
    "                if actual_image.get_attribute('src') and 'http' in actual_image.get_attribute('src'):\n",
    "                    image_urls.add(actual_image.get_attribute('src'))\n",
    "                    \n",
    "            image_count = len(image_urls)\n",
    "            \n",
    "            # break the loops when hit the max number of link\n",
    "            if len(image_urls) >= max_links_to_fetch:\n",
    "                print(f\"Found: {len(image_urls)} image links, done!\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Found:\", len(image_urls), \"image links, looking for more ...\")\n",
    "            # After scrolling down quite a lot, there will be a \"show more result\" button --> css = input.mye4qd\n",
    "            load_more_button = wd.find_element_by_css_selector(\".mye4qd\")\n",
    "            if load_more_button: # do similar to scroll more\n",
    "                wd.execute_script(\"document.querySelector('.mye4qd').click();\")\n",
    "\n",
    "        # move the result startpoint further down\n",
    "        results_start = len(thumbnail_results)\n",
    "\n",
    "    return image_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb36150",
   "metadata": {},
   "source": [
    "# Downloading the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a48538e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(folder_path:str, gray_folder_path:str, url:str):\n",
    "    \"\"\"\n",
    "    Download Images as color and as gray to train/test\n",
    "    Argument:\n",
    "    - folder_path = color folder (download as it is online)\n",
    "    - gray_folder_path = gray images folder (convert original to gray)\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - Could not download {url} - {e}\")\n",
    "\n",
    "    try:\n",
    "        image_file = io.BytesIO(image_content)\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "        gray_image = Image.open(image_file).convert('LA').convert('RGB')\n",
    "        \n",
    "        file_path = os.path.join(folder_path, hashlib.sha1(image_content).hexdigest()[:10] + '.jpg')\n",
    "        gray_file_path = os.path.join(gray_folder_path, hashlib.sha1(image_content).hexdigest()[:10] + '.jpg')\n",
    "                                   \n",
    "        with open(file_path, 'wb') as f:\n",
    "            image.save(f, \"JPEG\", quality=85)\n",
    "            \n",
    "        with open(gray_file_path, 'wb') as f:\n",
    "            gray_image.save(f, \"JPEG\", quality=85)\n",
    "            \n",
    "#         print(f\"SUCCESS - saved {url} - as {file_path} and {gray_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - Could not save {url} - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba6ac14",
   "metadata": {},
   "source": [
    "# Combine Search Url and Download Images:\n",
    "* Return 1 large folder with name = search keyword\n",
    "* Inside that folder is 2 other: color and gray folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0912d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_download(search_term:str, driver_path:str, target_path='./images', number_images=5):\n",
    "    \"\"\"\n",
    "    Combine search and download and drop all in 1 large folder with name = search keyword\n",
    "    Argument:\n",
    "    - search_term: search keyword for google image\n",
    "    - driver_path: global variable of where we put that ChromeDriver.exe\n",
    "    - target_path: create a \"images\" folder where this notebook lies, then inside are smaller folder with names = search_term\n",
    "    - number_images: how many images you want?\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # create folder\n",
    "    target_folder = os.path.join(target_path, '_'.join(search_term.lower().split(' ')), str('Color'))\n",
    "    gray_target_folder = os.path.join(target_path, '_'.join(search_term.lower().split(' ')), str('Gray'))\n",
    "\n",
    "    if not os.path.exists(target_folder): # if the folder images not exist, create it\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    if not os.path.exists(gray_target_folder): # if the folder images not exist, create it\n",
    "        os.makedirs(gray_target_folder)\n",
    "        \n",
    "    # use webdriver with google search and fetch image links\n",
    "    with webdriver.Chrome(executable_path=driver_path) as wd:\n",
    "        res = fetch_image_urls(search_term, number_images, wd=wd)\n",
    "    \n",
    "    # for each link, download it down\n",
    "    for elem in res:\n",
    "        download_image(target_folder, gray_target_folder, elem)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5078c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 84 image links, looking for more ...\n",
      "Found: 100 image links, done!\n"
     ]
    }
   ],
   "source": [
    "search_and_download(search_term = 'cat', driver_path=DRIVER_PATH, number_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38edc8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 100 image links, done!\n"
     ]
    }
   ],
   "source": [
    "search_and_download(search_term = 'portrait', driver_path=DRIVER_PATH, number_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a37fec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 81 image links, looking for more ...\n",
      "Found: 100 image links, done!\n"
     ]
    }
   ],
   "source": [
    "search_and_download(search_term = 'nature', driver_path=DRIVER_PATH, number_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31ba35ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 40 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 59 image links, looking for more ...\n",
      "Found: 70 image links, looking for more ...\n",
      "Found: 79 image links, looking for more ...\n",
      "Found: 79 image links, looking for more ...\n",
      "Found: 79 image links, looking for more ...\n",
      "Found: 79 image links, looking for more ...\n",
      "Found: 79 image links, looking for more ...\n",
      "Found: 79 image links, looking for more ...\n",
      "Found: 79 image links, looking for more ...\n",
      "Found: 79 image links, looking for more ...\n",
      "Found: 90 image links, looking for more ...\n",
      "Found: 100 image links, done!\n"
     ]
    }
   ],
   "source": [
    "search_and_download(search_term = 'dog', driver_path=DRIVER_PATH, number_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db532ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 29 image links, looking for more ...\n",
      "Found: 30 image links, looking for more ...\n",
      "Found: 30 image links, looking for more ...\n",
      "Found: 30 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 42 image links, looking for more ...\n",
      "Found: 53 image links, looking for more ...\n",
      "Found: 63 image links, looking for more ...\n",
      "Found: 63 image links, looking for more ...\n",
      "Found: 63 image links, looking for more ...\n",
      "Found: 63 image links, looking for more ...\n",
      "Found: 63 image links, looking for more ...\n",
      "Found: 75 image links, looking for more ...\n",
      "Found: 88 image links, looking for more ...\n",
      "Found: 99 image links, looking for more ...\n",
      "Found: 102 image links, done!\n"
     ]
    }
   ],
   "source": [
    "search_and_download(search_term = 'photograph', driver_path=DRIVER_PATH, number_images=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325514d",
   "metadata": {},
   "source": [
    "### Hey, 1000 (500color and 500gray) images in around 3-5minutes actually, so all fine! \n",
    "\n",
    "Just little calculation here: for 10,000 picture (5,000 color and 5,000gray) cost around 50minutes. Lmao, so let's only do that much. =)) I think that's plentiful already!<br>\n",
    "Also, we can increase the subject for sure, or just search something random like \"photograph\" like above, it's pretty random, and \"portrait\" is a must! lol HAVE FUNNNNNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PIC16B)",
   "language": "python",
   "name": "pic16b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
